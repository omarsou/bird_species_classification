{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nimport numpy as np\nfrom keras.layers import (\n    Dense,\n    Activation,\n    Dropout,\n    Flatten,\n    AveragePooling2D,\n)\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.applications import InceptionV3, Xception\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras import backend as K\nfrom keras.utils.generic_utils import get_custom_objects","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Seed value (can actually be different for each attribution step)\nseed_value= 0\n# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\nimport os\nos.environ['PYTHONHASHSEED']=str(seed_value)\n# 2. Set `python` built-in pseudo-random generator at a fixed value\nimport random\nrandom.seed(seed_value)\n# 3. Set `numpy` pseudo-random generator at a fixed value\nnp.random.seed(seed_value)\n# 4. Set `tensorflow` pseudo-random generator at a fixed value\nimport tensorflow as tf\ntf.random.set_seed(seed_value) # tensorflow 2.x\n# tf.set_random_seed(seed_value) # tensorflow 1.x","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utils"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Swish Activation Function\ndef swish(x):\n    return K.sigmoid(x) * x\n\nget_custom_objects().update({\"swish\": Activation(swish)})\n\n\n# Learning Step Decay by 10e-1 after every 4 epochs\ndef step_decay(epoch):\n    initial_lrate = 0.001\n    drop = 0.1\n    epochs_drop = 4.0\n    lrate = initial_lrate * math.pow(drop, math.floor((epoch) / epochs_drop))\n    return lrate\n\n# Calculates Precision Accuracy\ndef precision(y_true, y_pred):\n    \"\"\"Precision metric.\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n\n# Calculates Recall Accuracy\ndef recall(y_true, y_pred):\n    \"\"\"Recall metric.\n    Computes the recall, a metric for multi-label classification of\n    how many relevant items are selected.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\n\n# Calculates F1 score\ndef f1(y_true, y_pred):\n    def precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    def recall(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading models"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = InceptionResNetV2(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=None,\n        input_shape=(334,334,3)\n    )\nfor layer in base_model.layers[:len(base_model.layers)-26]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-26:]:\n    layer.trainable = True\n\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((8, 8), strides=(8, 8), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_resnet_original = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile Model\nadam = Adam(0.0001)\nmodel_resnet_original.compile(loss=\"categorical_crossentropy\",\n              optimizer=adam,\n             metrics=[precision, recall, f1, 'acc'])\nmodel_resnet_original.load_weights('../input/models/inception_resnet_retrained.h5')","execution_count":4,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n219062272/219055592 [==============================] - 8s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = InceptionResNetV2(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=None,\n        input_shape=(224,224,3)\n    )\nfor layer in base_model.layers[:len(base_model.layers)-26]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-26:]:\n    layer.trainable = True\n\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((4, 4), strides=(4, 4), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_resnet_cropped = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile Model\nadam = Adam(0.0001)\nmodel_resnet_cropped.compile(loss=\"categorical_crossentropy\",\n              optimizer=adam,\n             metrics=[precision, recall, f1, 'acc'])\nmodel_resnet_cropped.load_weights('../input/models/inception_resnet_cropped_retrained.h5')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = InceptionV3(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=None,\n        input_shape=(334,334,3)\n    )\nfor layer in base_model.layers[:len(base_model.layers)-17]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-17:]:\n    layer.trainable = True\n\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((8, 8), strides=(8, 8), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_inception_original = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile Model\nadam = Adam(0.0001)\nmodel_inception_original.compile(loss=\"categorical_crossentropy\",\n              optimizer=adam,\n             metrics=[precision, recall, f1, 'acc'])\nmodel_inception_original.load_weights('../input/models/inception_v3_retrained_v2.h5')","execution_count":6,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87916544/87910968 [==============================] - 4s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = InceptionV3(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=None,\n        input_shape=(224,224,3)\n    )\nfor layer in base_model.layers[:len(base_model.layers)-17]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-17:]:\n    layer.trainable = True\n\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((4, 4), strides=(4, 4), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_inception_cropped = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile Model\nadam = Adam(0.0001)\nmodel_inception_cropped.compile(loss=\"categorical_crossentropy\",\n              optimizer=adam,\n             metrics=[precision, recall, f1, 'acc'])\nmodel_inception_cropped.load_weights('../input/models/inception_v3_cropped_retrained.h5')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = Xception(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=None,\n        input_shape=(334,334,3)\n    )\nfor layer in base_model.layers[:len(base_model.layers)-30]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-30:]:\n    layer.trainable = True\n\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((8, 8), strides=(8, 8), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_xception_original = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile Model\nadam = Adam(0.0001)\nmodel_xception_original.compile(loss=\"categorical_crossentropy\",\n              optimizer=adam,\n             metrics=[precision, recall, f1, 'acc'])\nmodel_xception_original.load_weights('../input/xception/inception_xception_retrained.h5')","execution_count":8,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n83689472/83683744 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model = Xception(\n        include_top=False,\n        weights='imagenet',\n        input_tensor=None,\n        input_shape=(224,224,3)\n    )\nfor layer in base_model.layers[:len(base_model.layers)-30]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-30:]:\n    layer.trainable = True\n\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((4, 4), strides=(4, 4), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_xception_cropped = Model(inputs=base_model.input, outputs=predictions)\n\n# Compile Model\nadam = Adam(0.0001)\nmodel_xception_cropped.compile(loss=\"categorical_crossentropy\",\n              optimizer=adam,\n             metrics=[precision, recall, f1, 'acc'])\nmodel_xception_cropped.load_weights('../input/xception/inception_xception_cropped_retrained.h5')","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst_models = [model_resnet_original, model_resnet_cropped, model_inception_original, model_inception_cropped,\n             model_xception_original, model_xception_cropped]","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows, img_cols = (334,334)\ntrain_batchsize = 16\nval_batchsize = 16\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=30,\n      width_shift_range=0.3,\n      height_shift_range=0.3,\n      brightness_range=[0.2, 1.2],\n      horizontal_flip=True)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/train_images',\n        target_size=(img_rows, img_cols),\n        batch_size=train_batchsize,\n        class_mode='categorical',\n        interpolation='bicubic')\n \nvalidation_generator = validation_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/val_images',\n        target_size=(img_rows, img_cols),\n        batch_size=val_batchsize,\n        class_mode='categorical',\n        shuffle=False,\n        interpolation='bicubic')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# New Approach\nI will try to freeze the layers that I have freezed and unfreeze layers before"},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model_inception_original.layers[len(model_inception_original.layers)-22:len(model_inception_original.layers)-5]:\n    layer.trainable = False\nfor layer in model_inception_original.layers[len(model_inception_original.layers)-32:len(model_inception_original.layers)-22]:\n    layer.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"lrate = LearningRateScheduler(step_decay)\ncheckpoint = ModelCheckpoint(\"./resnet_original.h5\",\n                             monitor=\"val_acc\",\n                             mode=\"max\",\n                             save_best_only = True,\n                             verbose=1)\n\nnb_train_samples = 1082\nnb_validation_samples= 103\nepochs=10\nbatch_size=16\n\nhistory = model_inception_original.fit_generator(train_generator,\n                                 steps_per_epoch=nb_train_samples // batch_size,\n                                 epochs=epochs,\n                                 callbacks=[lrate, checkpoint],\n                                 validation_data=validation_generator,\n                                 validation_steps=nb_validation_samples // batch_size)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"well it's not better, I think it will only make the model overfit, so I will keep this for now"},{"metadata":{},"cell_type":"markdown","source":"# Make Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows, img_cols = (334,334)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n \ntest_generator = test_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/test_images',\n        target_size=(img_rows, img_cols),\n        batch_size=1,\n        class_mode=None,\n        shuffle=False,\n        interpolation='bicubic')","execution_count":11,"outputs":[{"output_type":"stream","text":"Found 517 images belonging to 1 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_inception_original = model_inception_original.predict(test_generator)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_resnet_original = model_resnet_original.predict(test_generator)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_xception_original = model_xception_original.predict(test_generator)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows, img_cols = (224,224)\n\ntest_datagen_crop = ImageDataGenerator(rescale=1./255)\n \ntest_generator_crop = test_datagen_crop.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/test_images_cropped',\n        target_size=(img_rows, img_cols),\n        batch_size=1,\n        class_mode=None,\n        shuffle=False,\n        interpolation='bicubic')","execution_count":15,"outputs":[{"output_type":"stream","text":"Found 459 images belonging to 1 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_inception_crop = model_inception_cropped.predict(test_generator_crop)\npredictions_resnet_crop = model_resnet_cropped.predict(test_generator_crop)\npredictions_xception_crop = model_xception_cropped.predict(test_generator_crop)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_orig = [x.split('/')[1][:-4] for x in test_generator.filenames]\nfilenames_crop = [x.split('/')[1][:-4] for x in test_generator_crop.filenames]","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble Model"},{"metadata":{},"cell_type":"markdown","source":"## First Strategy : Max Probability"},{"metadata":{"trusted":true},"cell_type":"code","source":"category = []\nall_probas = []\nfor idx, elem in enumerate(filenames_orig):\n    inception_orig = (np.max(predictions_inception_original[idx]), np.argmax(predictions_inception_original[idx]))\n    resnet_orig = (np.max(predictions_resnet_original[idx]), np.argmax(predictions_resnet_original[idx]))\n    xception_orig = (np.max(predictions_xception_original[idx]), np.argmax(predictions_xception_original[idx]))\n    try:\n        indice = filenames_crop.index(elem)\n        inception_crop = (np.max(predictions_inception_crop[indice]), np.argmax(predictions_inception_crop[indice]))\n        resnet_crop = (np.max(predictions_resnet_crop[indice]), np.argmax(predictions_resnet_crop[indice]))\n        xception_crop = (np.max(predictions_xception_crop[indice]), np.argmax(predictions_xception_crop[indice]))\n        all_proba = [inception_orig, resnet_orig, xception_orig, inception_crop, resnet_crop, xception_crop]\n    except ValueError:\n        all_proba = [inception_orig, resnet_orig, xception_orig]\n    max_proba, cat = all_proba[0]\n    for prob, label in all_proba[1:]:\n        if prob > max_proba:\n            max_proba = prob\n            cat = label\n    all_probas.append(all_proba)\n    category.append(cat)\n        ","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.DataFrame({'Id': filenames_orig, 'Category': category})\ndf.head()","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"                                 Id  Category\n0  002f61512a368e4c1434eedacf609957         5\n1  0247efd7b9d47d036bb4390202a13e69        10\n2  0267548c2aac82fe3d7e37ae98b00bd7        17\n3  030c7d18b20ee586db3b74d9966c0348        18\n4  034abbbb69336b0de7c7c0f2aa1267a6        17","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>002f61512a368e4c1434eedacf609957</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0247efd7b9d47d036bb4390202a13e69</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0267548c2aac82fe3d7e37ae98b00bd7</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>030c7d18b20ee586db3b74d9966c0348</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>034abbbb69336b0de7c7c0f2aa1267a6</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('./submissions_11.csv', index=False)","execution_count":22,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.80645"},{"metadata":{},"cell_type":"markdown","source":"## Second Strategy : Voting"},{"metadata":{"trusted":true},"cell_type":"code","source":"category_ = []\ndef most_frequent(List): \n    return max(set(List), key = List.count)\nfor idx, elem in enumerate(filenames_orig):\n    labels = [np.argmax(predictions_inception_original[idx]), np.argmax(predictions_resnet_original[idx]), \n             np.argmax(predictions_xception_original[idx])]\n    probs = [np.max(predictions_inception_original[idx]), np.max(predictions_resnet_original[idx]),\n            np.max(predictions_xception_original[idx])]\n    try:\n        indice = filenames_crop.index(elem)\n        labels += [np.argmax(predictions_inception_crop[indice]), np.argmax(predictions_resnet_crop[indice]),\n                  np.argmax(predictions_xception_crop[indice])]\n        probs += [np.max(predictions_inception_crop[indice]), np.max(predictions_resnet_crop[indice]), \n                 np.max(predictions_xception_crop[indice])]                      \n    except ValueError:\n        pass\n    if len(list(set(labels))) < len(labels):\n        category_.append(most_frequent(labels))\n    else:\n        max_indice = probs.index(max(probs))\n        category_.append(labels[max_indice])","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ = pd.DataFrame({'Id': filenames_orig, 'Category': category_})\ndf_.head()","execution_count":29,"outputs":[{"output_type":"execute_result","execution_count":29,"data":{"text/plain":"                                 Id  Category\n0  002f61512a368e4c1434eedacf609957         5\n1  0247efd7b9d47d036bb4390202a13e69        10\n2  0267548c2aac82fe3d7e37ae98b00bd7        17\n3  030c7d18b20ee586db3b74d9966c0348        18\n4  034abbbb69336b0de7c7c0f2aa1267a6        17","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>002f61512a368e4c1434eedacf609957</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0247efd7b9d47d036bb4390202a13e69</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0267548c2aac82fe3d7e37ae98b00bd7</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>030c7d18b20ee586db3b74d9966c0348</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>034abbbb69336b0de7c7c0f2aa1267a6</td>\n      <td>17</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_.to_csv('./submissions_12.csv', index=False)","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.81290"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}