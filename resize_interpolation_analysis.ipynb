{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"resize_interpolation_analysis.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPSpmc+NYgQF3KsSEioyFVS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"01RNtxNKCiFS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605110710188,"user_tz":-60,"elapsed":143292,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"1c6d816f-0429-439d-d534-d1d87623f38f"},"source":["import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import random\n","import torch\n","import seaborn as sns\n","%matplotlib inline\n","sns.set_context('poster')\n","sns.set_color_codes()\n","from google.colab import drive\n","drive.mount(\"/content/drive/\")\n","\n","orig_path = '/content/drive/My Drive/bird_classification/' + '/data/bird_dataset/'\n","\n","## For reproductibility\n","torch.manual_seed(2)\n","np.random.seed(2)\n","random.seed(2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"L524C_BvD_Ct"},"source":["import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from tqdm import tqdm\n","import torchvision.transforms as transforms"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IHoRXzwsD2D5"},"source":["# Utils functions"]},{"cell_type":"code","metadata":{"id":"iS9jIpkWD1WX"},"source":["def data_load(size=(300,300), interpolation=1, batch_size=16):\n","  data_transforms_train = transforms.Compose([\n","    transforms.Resize(size, interpolation=interpolation),  ## https://pillow.readthedocs.io/en/latest/handbook/concepts.html#filters\n","    transforms.RandomRotation(45),\n","    transforms.RandomVerticalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])\n","    ])\n","  data_transforms_val = transforms.Compose([\n","    transforms.Resize(size, interpolation=interpolation),  ## https://pillow.readthedocs.io/en/latest/handbook/concepts.html#filters\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                                 std=[0.229, 0.224, 0.225])])\n","  train_loader = torch.utils.data.DataLoader(\n","    datasets.ImageFolder(orig_path + '/train_images',\n","                         transform=data_transforms_train),\n","    batch_size=batch_size, shuffle=True)\n","  val_loader = torch.utils.data.DataLoader(\n","    datasets.ImageFolder(orig_path + '/val_images',\n","                         transform=data_transforms_val),\n","    batch_size=batch_size, shuffle=False)\n","  return train_loader, val_loader\n","\n","def visualize_history(loss_train, loss_val, acc_train, acc_val):\n","  # Visual comparison\n","  titles = [\"Loss Evolution\", \"Accuracy Evolution\"]\n","  y = [[loss_train, loss_val], [acc_train, acc_val]]\n","  label_loss = [['Train Loss', 'Val Loss'], ['Train Accuracy', 'Validation Accuracy']]\n","  ncols = len(titles)\n","  fig, axes = plt.subplots(1, ncols, figsize=(15, 5))\n","  steps = np.arange(1,len(loss_train))\n","  for idx, ax in enumerate(axes.flatten()):\n","    title = titles[idx]\n","    ax.plot(steps, y[idx][0], label=label_loss[idx][0], color='b')\n","    ax.plot(steps, y[idx][1], label=label_loss[idx][1], color='r')\n","    ax.set_title(title)\n","    ax.legend()\n","  fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kw2UFRUyFm8e"},"source":["def train(epoch, model, train_loader):\n","    model.train()\n","    correct = 0\n","    loss_values = 0\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.cuda(), target.cuda()\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pred = output.data.max(1, keepdim=True)[1]\n","        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","        if batch_idx % 20 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.data.item()))\n","        loss_values += loss.data.item()\n","    avg_acc = 100*correct / len(train_loader.dataset)\n","    avg_loss = loss_values / len(train_loader.dataset)\n","    print(f'Average Accuracy : {avg_acc}')\n","    return (avg_acc, avg_loss)\n","        \n","\n","def validation(model, val_loader):\n","    model.eval()\n","    validation_loss = 0\n","    correct = 0\n","    for data, target in val_loader:\n","        data, target = data.cuda(), target.cuda()\n","        output = model(data)\n","        validation_loss += criterion(output, target).data.item()\n","        # get the index of the max log-probability\n","        pred = output.data.max(1, keepdim=True)[1]\n","        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n","    avg_acc = 100. * correct / len(val_loader.dataset)\n","    validation_loss /= len(val_loader.dataset)\n","    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n","        validation_loss, correct, len(val_loader.dataset),\n","        avg_acc))\n","    return (avg_acc, validation_loss)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mUpYRUS4FB7C"},"source":["# Interpolation"]},{"cell_type":"markdown","metadata":{"id":"R0dBNWwGFFfm"},"source":["## BOX\n","Each pixel of source image contributes to one pixel of the destination image with identical weights."]},{"cell_type":"code","metadata":{"id":"oj8J-zLWFE6C"},"source":["train_loader, val_loader = data_load()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-YayTpeeDywq"},"source":["from torchvision.models import resnet152"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rR03-cXvFfsq"},"source":["model_resnet = resnet152(pretrained=True)\n","i_max = len(list(model_resnet.parameters())) - 33\n","i = 0\n","for param in model_resnet.parameters():\n","  if i > i_max:\n","    break\n","  i += 1\n","  param.requires_grad = False\n","num_features = model_resnet.fc.in_features\n","model_resnet.fc = nn.Linear(num_features, 20)\n","model_resnet.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k58wvRO7GEmT"},"source":["param_optimizer = list(model_resnet.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","lr = 0.001\n","optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=lr)\n","\n","criterion = torch.nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nkJcSshvGH3x"},"source":["acc_train = []\n","loss_train = []\n","acc_val = []\n","loss_val = []\n","best_acc_val = 45\n","for epoch in range(1, 12):\n","    acc_t, loss_t = train(epoch, model_resnet)\n","    acc_v, loss_v = validation(model_resnet)\n","    acc_train.append(acc_t.item())\n","    loss_train.append(loss_t)\n","    acc_val.append(acc_v.item())\n","    loss_val.append(loss_v)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fd-z2Wd6MRnQ"},"source":["history_box = {'t_l': loss_train, 't_a' : acc_train, 'v_l': loss_val, 'v_a': acc_val}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SfyWAG9pJrzh"},"source":["## Nearest"]},{"cell_type":"code","metadata":{"id":"ZqJODagMJtKy"},"source":["train_loader, val_loader = data_load(interpolation=0)\n","model_resnet = resnet152(pretrained=True)\n","i_max = len(list(model_resnet.parameters())) - 33\n","i = 0\n","for param in model_resnet.parameters():\n","  if i > i_max:\n","    break\n","  i += 1\n","  param.requires_grad = False\n","num_features = model_resnet.fc.in_features\n","model_resnet.fc = nn.Linear(num_features, 20)\n","model_resnet.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdRWWyZZM-kt"},"source":["param_optimizer = list(model_resnet.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","lr = 0.001\n","optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=lr)\n","\n","criterion = torch.nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"js1YpE_VKBiO"},"source":["acc_train = []\n","loss_train = []\n","acc_val = []\n","loss_val = []\n","best_acc_val = 45\n","for epoch in range(1,12):\n","    acc_t, loss_t = train(epoch, model_resnet)\n","    acc_v, loss_v = validation(model_resnet)\n","    acc_train.append(acc_t.item())\n","    loss_train.append(loss_t)\n","    acc_val.append(acc_v.item())\n","    loss_val.append(loss_v)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LxutZvzNZkP"},"source":["history_near = {'t_l': loss_train, 't_a' : acc_train, 'v_l': loss_val, 'v_a': acc_val}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hkM81EFHVk6z"},"source":["### Bilinear"]},{"cell_type":"code","metadata":{"id":"PAq8kg7IVibs"},"source":["train_loader, val_loader = data_load(interpolation=2)\n","model_resnet = resnet152(pretrained=True)\n","i_max = len(list(model_resnet.parameters())) - 33\n","i = 0\n","for param in model_resnet.parameters():\n","  if i > i_max:\n","    break\n","  i += 1\n","  param.requires_grad = False\n","num_features = model_resnet.fc.in_features\n","model_resnet.fc = nn.Linear(num_features, 20)\n","model_resnet.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXyN6NYoPIZ5"},"source":["param_optimizer = list(model_resnet.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","lr = 0.001\n","optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=lr)\n","\n","criterion = torch.nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZGwdZGKfVuOi"},"source":["acc_train = []\n","loss_train = []\n","acc_val = []\n","loss_val = []\n","best_acc_val = 45\n","for epoch in range(1,12):\n","    acc_t, loss_t = train(epoch, model_resnet)\n","    acc_v, loss_v = validation(model_resnet)\n","    acc_train.append(acc_t.item())\n","    loss_train.append(loss_t)\n","    acc_val.append(acc_v.item())\n","    loss_val.append(loss_v)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qq_nySFhVwk_"},"source":["history_bilinear = {'t_l': loss_train, 't_a' : acc_train, 'v_l': loss_val, 'v_a': acc_val}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mP5YEQwdYXZV"},"source":["Winner is cubic interpolation since it has achieve 86.4 % of accuracy.\n","Now let's see if we can improve the accuracy by changing de size of our image"]},{"cell_type":"markdown","metadata":{"id":"DFfjX458Yj0J"},"source":["# Size"]},{"cell_type":"markdown","metadata":{"id":"TElb5Il5Ylnv"},"source":["## (64,64)"]},{"cell_type":"code","metadata":{"id":"OUJZaWTFYjOd"},"source":["train_loader, val_loader = data_load(size=(64,64), interpolation=4)\n","model_resnet = resnet152(pretrained=True)\n","i_max = len(list(model_resnet.parameters())) - 33\n","i = 0\n","for param in model_resnet.parameters():\n","  if i > i_max:\n","    break\n","  i += 1\n","  param.requires_grad = False\n","num_features = model_resnet.fc.in_features\n","model_resnet.fc = nn.Linear(num_features, 20)\n","model_resnet.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jBD4e5SQYih4"},"source":["param_optimizer = list(model_resnet.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","lr = 0.001\n","optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=lr)\n","\n","criterion = torch.nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WUFBzxXGY4Ci"},"source":["acc_train = []\n","loss_train = []\n","acc_val = []\n","loss_val = []\n","best_acc_val = 0\n","for epoch in range(1,12):\n","    acc_t, loss_t = train(epoch, model_resnet)\n","    acc_v, loss_v = validation(model_resnet)\n","    acc_train.append(acc_t.item())\n","    loss_train.append(loss_t)\n","    acc_val.append(acc_v.item())\n","    loss_val.append(loss_v)\n","    if acc_v.item()>best_acc_val:\n","      best_acc_val = acc_v.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6ZwXHMEpZDge"},"source":["history_64_64 = {'t_l': loss_train, 't_a' : acc_train, 'v_l': loss_val, 'v_a': acc_val}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jz8aheGnaOrl"},"source":["### (128,128)"]},{"cell_type":"code","metadata":{"id":"DtEVDAF0aRR3"},"source":["train_loader, val_loader = data_load(size=(128,128), interpolation=4)\n","model_resnet = resnet152(pretrained=True)\n","i_max = len(list(model_resnet.parameters())) - 33\n","i = 0\n","for param in model_resnet.parameters():\n","  if i > i_max:\n","    break\n","  i += 1\n","  param.requires_grad = False\n","num_features = model_resnet.fc.in_features\n","model_resnet.fc = nn.Linear(num_features, 20)\n","model_resnet.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSoEsVb8aanA"},"source":["param_optimizer = list(model_resnet.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","lr = 0.001\n","optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=lr)\n","\n","criterion = torch.nn.CrossEntropyLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ED15qvcGaeuY"},"source":["acc_train = []\n","loss_train = []\n","acc_val = []\n","loss_val = []\n","best_acc_val = 0\n","for epoch in range(1,12):\n","    acc_t, loss_t = train(epoch, model_resnet,train_loader)\n","    acc_v, loss_v = validation(model_resnet, val_loader)\n","    acc_train.append(acc_t.item())\n","    loss_train.append(loss_t)\n","    acc_val.append(acc_v.item())\n","    loss_val.append(loss_v)\n","    if acc_v.item()>best_acc_val:\n","      best_acc_val = acc_v.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yyidEVWNb9UW"},"source":["history_128_128 = {'t_l': loss_train, 't_a' : acc_train, 'v_l': loss_val, 'v_a': acc_val}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LLDR6GxWcCE_"},"source":["### (224,224)"]},{"cell_type":"code","metadata":{"id":"F4ReGbpNcBXl"},"source":["train_loader, val_loader = data_load(size=(224,224), interpolation=4)\n","model_resnet = resnet152(pretrained=True)\n","i_max = len(list(model_resnet.parameters())) - 33\n","i = 0\n","for param in model_resnet.parameters():\n","  if i > i_max:\n","    break\n","  i += 1\n","  param.requires_grad = False\n","num_features = model_resnet.fc.in_features\n","model_resnet.fc = nn.Linear(num_features, 20)\n","model_resnet.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_wnx3uccK4p"},"source":["param_optimizer = list(model_resnet.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","lr = 0.001\n","optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=lr)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","acc_train = []\n","loss_train = []\n","acc_val = []\n","loss_val = []\n","best_acc_val = 0\n","for epoch in range(1,12):\n","    acc_t, loss_t = train(epoch, model_resnet,train_loader)\n","    acc_v, loss_v = validation(model_resnet, val_loader)\n","    acc_train.append(acc_t.item())\n","    loss_train.append(loss_t)\n","    acc_val.append(acc_v.item())\n","    loss_val.append(loss_v)\n","    if acc_v.item()>best_acc_val:\n","      best_acc_val = acc_v.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jc77D823cQr0"},"source":["history_224_224 = {'t_l': loss_train, 't_a' : acc_train, 'v_l': loss_val, 'v_a': acc_val}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hEJdarBwdbds"},"source":["### (334,334)"]},{"cell_type":"code","metadata":{"id":"2QojgUBIdYJa"},"source":["train_loader, val_loader = data_load(size=(334,334), interpolation=4)\n","model_resnet = resnet152(pretrained=True)\n","i_max = len(list(model_resnet.parameters())) - 33\n","i = 0\n","for param in model_resnet.parameters():\n","  if i > i_max:\n","    break\n","  i += 1\n","  param.requires_grad = False\n","num_features = model_resnet.fc.in_features\n","model_resnet.fc = nn.Linear(num_features, 20)\n","model_resnet.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YQFECODKdsk1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605118675646,"user_tz":-60,"elapsed":1036954,"user":{"displayName":"Omar Souaidi","photoUrl":"","userId":"18313246010754186886"}},"outputId":"5088ce4a-8fae-43bb-d0ca-f1cdf0b42eb8"},"source":["param_optimizer = list(model_resnet.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}]\n","lr = 0.001\n","optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=lr)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","acc_train = []\n","loss_train = []\n","acc_val = []\n","loss_val = []\n","best_acc_val = 0\n","for epoch in range(1,12):\n","    acc_t, loss_t = train(epoch, model_resnet,train_loader)\n","    acc_v, loss_v = validation(model_resnet, val_loader)\n","    acc_train.append(acc_t.item())\n","    loss_train.append(loss_t)\n","    acc_val.append(acc_v.item())\n","    loss_val.append(loss_v)\n","    if acc_v.item()>best_acc_val:\n","      best_acc_val = acc_v.item()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Epoch: 1 [0/1082 (0%)]\tLoss: 3.027610\n","Train Epoch: 1 [320/1082 (29%)]\tLoss: 1.964068\n","Train Epoch: 1 [640/1082 (59%)]\tLoss: 1.549480\n","Train Epoch: 1 [960/1082 (88%)]\tLoss: 1.679340\n","Average Accuracy : 44.17744827270508\n","\n","Validation set: Average loss: 0.1165, Accuracy: 60/103 (58%)\n","Train Epoch: 2 [0/1082 (0%)]\tLoss: 1.367237\n","Train Epoch: 2 [320/1082 (29%)]\tLoss: 0.872879\n","Train Epoch: 2 [640/1082 (59%)]\tLoss: 0.690016\n","Train Epoch: 2 [960/1082 (88%)]\tLoss: 1.357473\n","Average Accuracy : 70.05545043945312\n","\n","Validation set: Average loss: 0.0951, Accuracy: 59/103 (57%)\n","Train Epoch: 3 [0/1082 (0%)]\tLoss: 0.938491\n","Train Epoch: 3 [320/1082 (29%)]\tLoss: 0.922523\n","Train Epoch: 3 [640/1082 (59%)]\tLoss: 0.962184\n","Train Epoch: 3 [960/1082 (88%)]\tLoss: 0.989885\n","Average Accuracy : 72.18114471435547\n","\n","Validation set: Average loss: 0.0791, Accuracy: 60/103 (58%)\n","Train Epoch: 4 [0/1082 (0%)]\tLoss: 0.355374\n","Train Epoch: 4 [320/1082 (29%)]\tLoss: 0.944697\n","Train Epoch: 4 [640/1082 (59%)]\tLoss: 0.647367\n","Train Epoch: 4 [960/1082 (88%)]\tLoss: 1.627472\n","Average Accuracy : 77.9112777709961\n","\n","Validation set: Average loss: 0.0348, Accuracy: 85/103 (83%)\n","Train Epoch: 5 [0/1082 (0%)]\tLoss: 0.725095\n","Train Epoch: 5 [320/1082 (29%)]\tLoss: 0.789922\n","Train Epoch: 5 [640/1082 (59%)]\tLoss: 0.871518\n","Train Epoch: 5 [960/1082 (88%)]\tLoss: 0.660364\n","Average Accuracy : 77.9112777709961\n","\n","Validation set: Average loss: 0.0434, Accuracy: 82/103 (80%)\n","Train Epoch: 6 [0/1082 (0%)]\tLoss: 0.369832\n","Train Epoch: 6 [320/1082 (29%)]\tLoss: 0.375600\n","Train Epoch: 6 [640/1082 (59%)]\tLoss: 0.360729\n","Train Epoch: 6 [960/1082 (88%)]\tLoss: 0.808929\n","Average Accuracy : 81.79297637939453\n","\n","Validation set: Average loss: 0.0352, Accuracy: 87/103 (84%)\n","Train Epoch: 7 [0/1082 (0%)]\tLoss: 0.608788\n","Train Epoch: 7 [320/1082 (29%)]\tLoss: 1.876617\n","Train Epoch: 7 [640/1082 (59%)]\tLoss: 0.480972\n","Train Epoch: 7 [960/1082 (88%)]\tLoss: 0.615227\n","Average Accuracy : 85.5822525024414\n","\n","Validation set: Average loss: 0.0297, Accuracy: 86/103 (83%)\n","Train Epoch: 8 [0/1082 (0%)]\tLoss: 0.315150\n","Train Epoch: 8 [320/1082 (29%)]\tLoss: 0.522786\n","Train Epoch: 8 [640/1082 (59%)]\tLoss: 0.783222\n","Train Epoch: 8 [960/1082 (88%)]\tLoss: 0.567568\n","Average Accuracy : 85.02772521972656\n","\n","Validation set: Average loss: 0.0499, Accuracy: 83/103 (81%)\n","Train Epoch: 9 [0/1082 (0%)]\tLoss: 0.287222\n","Train Epoch: 9 [320/1082 (29%)]\tLoss: 0.286714\n","Train Epoch: 9 [640/1082 (59%)]\tLoss: 0.308471\n","Train Epoch: 9 [960/1082 (88%)]\tLoss: 0.787418\n","Average Accuracy : 86.04436492919922\n","\n","Validation set: Average loss: 0.0412, Accuracy: 77/103 (75%)\n","Train Epoch: 10 [0/1082 (0%)]\tLoss: 0.490273\n","Train Epoch: 10 [320/1082 (29%)]\tLoss: 0.290593\n","Train Epoch: 10 [640/1082 (59%)]\tLoss: 0.461696\n","Train Epoch: 10 [960/1082 (88%)]\tLoss: 0.395568\n","Average Accuracy : 88.63216400146484\n","\n","Validation set: Average loss: 0.0306, Accuracy: 87/103 (84%)\n","Train Epoch: 11 [0/1082 (0%)]\tLoss: 0.285920\n","Train Epoch: 11 [320/1082 (29%)]\tLoss: 0.678207\n","Train Epoch: 11 [640/1082 (59%)]\tLoss: 0.176942\n","Train Epoch: 11 [960/1082 (88%)]\tLoss: 0.375873\n","Average Accuracy : 89.18669128417969\n","\n","Validation set: Average loss: 0.0441, Accuracy: 83/103 (81%)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C22Tx6GAiLbN"},"source":["Winner : (334,334)"]}]}