{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport random\nimport pandas as pd\nimport math\nimport os\nimport matplotlib.pyplot as plt\nimport cv2\nfrom shutil import copyfile\nfrom keras.callbacks import LearningRateScheduler\nimport keras\nfrom keras.layers import Flatten, Dense, Input, GlobalAveragePooling2D, \\\n    GlobalMaxPooling2D, Activation, Conv2D, MaxPooling2D, BatchNormalization, \\\n    AveragePooling2D, Reshape, Permute, multiply, ZeroPadding2D, Dropout, LeakyReLU\nfrom keras import applications\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras import backend as K\nimport warnings\nfrom keras.models import Model, Sequential, load_model, model_from_json\nfrom keras import layers\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nimport tensorflow as tf\nfrom keras.layers import Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D, Reshape\nfrom keras.applications import VGG16\nfrom keras.applications import InceptionV3\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.utils.generic_utils import get_custom_objects\n\n# Swish Activation Function\ndef swish(x):\n    return K.sigmoid(x) * x\n\nget_custom_objects().update({\"swish\": Activation(swish)})\n\n\n# Learning Step Decay by 10e-1 after every 4 epochs\ndef step_decay(epoch):\n    initial_lrate = 0.001\n    drop = 0.1\n    epochs_drop = 4.0\n    lrate = initial_lrate * math.pow(drop, math.floor((epoch) / epochs_drop))\n    return lrate\n\n# Calculates Precision Accuracy\ndef precision(y_true, y_pred):\n    \"\"\"Precision metric.\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n\n# Calculates Recall Accuracy\ndef recall(y_true, y_pred):\n    \"\"\"Recall metric.\n    Computes the recall, a metric for multi-label classification of\n    how many relevant items are selected.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\n\n# Calculates F1 score\ndef f1(y_true, y_pred):\n    def precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    def recall(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"img_rows, img_cols = (334,334)\ntrain_batchsize = 16\nval_batchsize = 16\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=30,\n      width_shift_range=0.3,\n      height_shift_range=0.3,\n      brightness_range=[0.2, 1.2],\n      horizontal_flip=True)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/train_images',\n        target_size=(img_rows, img_cols),\n        batch_size=train_batchsize,\n        class_mode='categorical',\n        interpolation='bicubic')\n \nvalidation_generator = validation_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/val_images',\n        target_size=(img_rows, img_cols),\n        batch_size=val_batchsize,\n        class_mode='categorical',\n        shuffle=False,\n        interpolation='bicubic')\n\nimg_rows, img_cols = (224, 224)\ntrain_batchsize = 16\nval_batchsize = 16\n\ntrain_datagen_crop = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=30,\n      width_shift_range=0.3,\n      height_shift_range=0.3,\n      brightness_range=[0.2, 1.2],\n      horizontal_flip=True)\n\nvalidation_datagen_crop = ImageDataGenerator(rescale=1./255)\n\ntrain_generator_crop = train_datagen_crop.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/train_images_cropped',\n        target_size=(img_rows, img_cols),\n        batch_size=train_batchsize,\n        class_mode='categorical',\n        interpolation='bicubic')\n \nvalidation_generator_crop = validation_datagen_crop.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/val_images_cropped',\n        target_size=(img_rows, img_cols),\n        batch_size=val_batchsize,\n        class_mode='categorical',\n        shuffle=False,\n        interpolation='bicubic')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shapes_resnet = [(9, 9, 1536), (5, 5, 1536)]\nshapes_inception = [(9, 9, 2048), (5, 5, 2048)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_attention(shape, size=(334,334,3), num_unfreeze=0):\n    base_pretrained_model = InceptionV3(input_shape =size, \n                              include_top = False, weights = 'imagenet')\n    for layer in base_pretrained_model.layers[:len(base_pretrained_model.layers)-num_unfreeze]:\n        layer.trainable = False\n    for layer in base_pretrained_model.layers[len(base_pretrained_model.layers)-num_unfreeze:]:\n        layer.trainable = True\n    model = Sequential()\n    pt_features = Input(shape , name = 'feature_input')\n    pt_depth = shape[-1]\n    bn_features = BatchNormalization()(pt_features)\n    # here we do an attention mechanism to turn pixels in the GAP on an off\n    attn_layer = Conv2D(128, kernel_size = (1,1), padding = 'same', activation = 'elu')(bn_features)\n    attn_layer = Conv2D(32, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\n    attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'elu')(attn_layer)\n    attn_layer = AvgPool2D((2,2), strides = (1,1), padding = 'same')(attn_layer) # smooth results\n    attn_layer = Conv2D(1, \n                        kernel_size = (1,1), \n                        padding = 'valid', \n                        activation = 'sigmoid')(attn_layer)\n    # branch it to all channel\n    up_c2_w = np.ones((1, 1, 1, pt_depth))\n    up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', \n                   activation = 'linear', use_bias = False, weights = [up_c2_w])\n    up_c2.trainable = False\n    attn_layer = up_c2(attn_layer)\n    mask_features = multiply([attn_layer, bn_features])\n    gap_features = GlobalAveragePooling2D()(mask_features)\n    gap_mask = GlobalAveragePooling2D()(attn_layer)\n    # to account for missing values from the attention model\n    gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n    gap_dr = Dropout(0.4)(gap)\n    dr_steps = Dropout(0.4)(Dense(512, activation = 'swish', kernel_initializer=\"he_uniform\")(gap_dr))\n    out_layer = Dense(20, activation = 'softmax', kernel_initializer=\"he_uniform\")(dr_steps)\n    attn_model = Model(inputs = [pt_features], outputs = [out_layer], name = 'attention_model')\n\n    attn_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n                               metrics = ['acc'])\n    \n    print('Summary of Attention model only: ')\n    print(attn_model.summary())\n    \n    \n\n    \n    tb_model = Sequential(name = 'combined_model')\n    for layer in base_pretrained_model.layers[:len(base_pretrained_model.layers)-num_unfreeze]:\n        layer.trainable = False\n    for layer in base_pretrained_model.layers[len(base_pretrained_model.layers)-num_unfreeze:]:\n        layer.trainable = True\n    tb_model.add(base_pretrained_model)\n    tb_model.add(attn_model)\n    tb_model.compile(optimizer = Adam(lr = 0.001), loss = 'categorical_crossentropy',\n                               metrics = [precision, recall, f1, 'acc'])\n    print(\"Summary of final model: \")\n    print(tb_model.summary())\n    \n    return tb_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_resnet_0 = model_attention(shapes_resnet[0], num_unfreeze=14)\nmodel_resnet_0.load_weights('../input/models-bird/resnet_original_v1_3.h5')\nmodel_resnet_2 = model_attention(shapes_resnet[1], size=(224,224,3), num_unfreeze=20)\nmodel_resnet_2.load_weights('../input/models-bird/resnet_cropped.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_inception_0 = model_attention(shapes_inception[0], num_unfreeze=30)\nmodel_inception_0.load_weights('../input/models-bird/inception_original_v1.h5')\nmodel_inception_2 = model_attention(shapes_inception[1], size=(224,224,3), num_unfreeze=30)\nmodel_inception_2.load_weights('../input/models-bird/inception_cropped.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_width, img_height = 334, 334\nbase_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\nfor layer in base_model.layers[:len(base_model.layers)-17]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-17:]:\n    layer.trainable = True\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((8, 8), strides=(8, 8), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_0 = Model(inputs=base_model.input, outputs=predictions)\noptimizer = Adam(0.0001)\nmodel_0.compile(loss=\"categorical_crossentropy\",\n              optimizer=optimizer,\n             metrics=[precision, recall, f1, 'acc'])\nmodel_0.load_weights('../input/models-bird/inception_v3_retrained_v2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dimensions of our images.\nimg_width, img_height = 224, 224\nbase_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\nfor layer in base_model.layers[:len(base_model.layers)-17]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-17:]:\n    layer.trainable = True\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((4, 4), strides=(4, 4), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_2 = Model(inputs=base_model.input, outputs=predictions)\noptimizer = Adam(0.0001)\nmodel_2.compile(loss=\"categorical_crossentropy\",\n              optimizer=optimizer,\n             metrics=[precision, recall, f1, 'acc'])\nmodel_2.load_weights('../input/models-bird/inception_v3_cropped_retrained.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Stacking models"},{"metadata":{"trusted":true},"cell_type":"code","source":"members_original = [model_resnet_0, model_inception_0, model_0]\nmembers_cropped = [model_resnet_2, model_inception_2, model_2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# update all layers in all models to not be trainable\nfor i in range(len(members_original)):\n    model = members_original[i]\n    for layer in model.layers:\n        # make not trainable\n        layer.trainable = False\n    model = members_cropped[i]\n    for layer in model.layers:\n        # make not trainable\n        layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers.merge import concatenate\nfrom keras.utils import plot_model\nfrom sklearn.metrics import accuracy_score\nfrom keras.layers import Input","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ORIGINAL"},{"metadata":{"trusted":true},"cell_type":"code","source":"inp1 = Input(shape=(20,), name=\"input1\")\ninp2 = Input(shape=(20,), name=\"input2\")\ninp3 = Input(shape=(20,), name=\"input3\")\ninput_ = concatenate([inp1, inp2, inp3])\nhidden = Dense(64, activation='relu')(input_)\noutput = Dense(20, activation='softmax')(hidden)\nmodel = Model(inputs=[inp1, inp2, inp3], outputs=output)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/val_images',\n        target_size=(334, 334),\n        batch_size=103,\n        class_mode='categorical',\n        shuffle=False,\n        interpolation='bicubic')\ninput_X, input_Y = None, None\nfor X, y in validation_generator:\n    input_X, input_Y = X, y\n    break\npredictions_resnet_0 = model_resnet_0.predict(input_X)\npredictions_inception_0 = model_inception_0.predict(input_X)\npredictions_0 = model_0.predict(input_X)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"res = [predictions_resnet_0, predictions_inception_0, predictions_0]\nmodel.fit(res, input_Y, epochs=100, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cropped"},{"metadata":{"trusted":true},"cell_type":"code","source":"inp1 = Input(shape=(20,), name=\"input1\")\ninp2 = Input(shape=(20,), name=\"input2\")\ninp3 = Input(shape=(20,), name=\"input3\")\ninput_ = concatenate([inp1, inp2, inp3])\nhidden = Dense(64, activation='relu')(input_)\noutput = Dense(20, activation='softmax')(hidden)\nmodel_crop = Model(inputs=[inp1, inp2, inp3], outputs=output)\nmodel_crop.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nvalidation_datagen_crop = ImageDataGenerator(rescale=1./255)\nvalidation_generator_crop = validation_datagen_crop.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/val_images_cropped',\n        target_size=(224, 224),\n        batch_size=92,\n        class_mode='categorical',\n        shuffle=False,\n        interpolation='bicubic')\ninput_X, input_Y = None, None\nfor X, y in validation_generator_crop:\n    input_X, input_Y = X, y\n    break\npredictions_resnet_2 = model_resnet_2.predict(input_X)\npredictions_inception_2 = model_inception_2.predict(input_X)\npredictions_2 = model_2.predict(input_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"res = [predictions_resnet_2, predictions_inception_2, predictions_2]\nmodel_crop.fit(res, input_Y, epochs=150, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions"},{"metadata":{},"cell_type":"markdown","source":"## Original"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/test_images',\n        target_size=(334, 334),\n        batch_size=517,\n        class_mode=None,\n        shuffle=False,\n        interpolation='bicubic')\npredictions_resnet_0 = model_resnet_0.predict(test_generator)\npredictions_inception_0 = model_inception_0.predict(test_generator)\npredictions_0 = model_0.predict(test_generator)\nres = [predictions_resnet_0, predictions_inception_0, predictions_0]\npredictions_original = model.predict(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## cropped"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen_crop = ImageDataGenerator(rescale=1./255)\ntest_generator_crop = test_datagen_crop.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/test_images_cropped',\n        target_size=(224, 224),\n        batch_size=459,\n        class_mode=None,\n        shuffle=False,\n        interpolation='bicubic')\npredictions_resnet_2 = model_resnet_2.predict(test_generator_crop)\npredictions_inception_2 = model_inception_2.predict(test_generator_crop)\npredictions_2 = model_2.predict(test_generator_crop)\nres = [predictions_resnet_2, predictions_inception_2, predictions_2]\npredictions_cropped = model_crop.predict(res)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames_orig = [x.split('/')[1][:-4] for x in test_generator.filenames]\nfilenames_crop = [x.split('/')[1][:-4] for x in test_generator_crop.filenames]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category = []\nall_probas = []\nfor idx, elem in enumerate(filenames_orig):\n    orig = (np.max(predictions_original[idx]), np.argmax(predictions_original[idx]))\n    try:\n        indice = filenames_crop.index(elem)\n        crop = (np.max(predictions_cropped[indice]), np.argmax(predictions_cropped[indice]))\n        all_proba = [orig, crop]\n    except ValueError:\n        all_proba = [orig]\n    max_proba, cat = all_proba[0]\n    for prob, label in all_proba[1:]:\n        if prob > max_proba:\n            max_proba = prob\n            cat = label\n    all_probas.append(all_proba)\n    category.append(cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'Id': filenames_orig, 'Category': category})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('./submissions_final.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SCORE : 0.84516"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}