{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport keras.initializers as KI\nimport keras.layers as KL\nimport keras.losses as KLoss\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras.layers import Convolution2D, GlobalAveragePooling2D, Dense, Activation, Dropout, Flatten, AveragePooling2D\nfrom keras.models import Model\nfrom keras.utils import conv_utils\nfrom keras import applications\nfrom keras import optimizers\nfrom keras.utils import multi_gpu_model\nfrom keras.utils.generic_utils import get_custom_objects\nfrom keras.optimizers import Adam\nimport math\nfrom keras.callbacks import LearningRateScheduler\n# Seed value (can actually be different for each attribution step)\nseed_value= 0\n# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\nos.environ['PYTHONHASHSEED']=str(seed_value)\n# 2. Set `python` built-in pseudo-random generator at a fixed value\nimport random\nrandom.seed(seed_value)\n# 3. Set `numpy` pseudo-random generator at a fixed value\nnp.random.seed(seed_value)\n# 4. Set `tensorflow` pseudo-random generator at a fixed value\ntf.random.set_seed(seed_value) # tensorflow 2.x\n# tf.set_random_seed(seed_value) # tensorflow 1.x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Utils"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Swish Activation Function\ndef swish(x):\n    return K.sigmoid(x) * x\n\nget_custom_objects().update({\"swish\": Activation(swish)})\n\n\n# Learning Step Decay by 10e-1 after every 4 epochs\ndef step_decay(epoch):\n    initial_lrate = 0.001\n    drop = 0.1\n    epochs_drop = 4.0\n    lrate = initial_lrate * math.pow(drop, math.floor((epoch) / epochs_drop))\n    return lrate\n\n# Calculates Precision Accuracy\ndef precision(y_true, y_pred):\n    \"\"\"Precision metric.\n    Computes the precision, a metric for multi-label classification of\n    how many selected items are relevant.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\n\n# Calculates Recall Accuracy\ndef recall(y_true, y_pred):\n    \"\"\"Recall metric.\n    Computes the recall, a metric for multi-label classification of\n    how many relevant items are selected.\n    \"\"\"\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\n\n# Calculates F1 score\ndef f1(y_true, y_pred):\n    def precision(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + K.epsilon())\n        return precision\n\n    def recall(y_true, y_pred):\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + K.epsilon())\n        return recall\n\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# InceptionV3 with Inaturalist dataset"},{"metadata":{},"cell_type":"markdown","source":"## Unfreezed"},{"metadata":{},"cell_type":"markdown","source":"## Inception V3"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"img_rows, img_cols = (334, 334)\ntrain_batchsize = 16\nval_batchsize = 16\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=30,\n      width_shift_range=0.3,\n      height_shift_range=0.3,\n      brightness_range=[0.2, 1.2],\n      horizontal_flip=True)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/train_images',\n        target_size=(img_rows, img_cols),\n        batch_size=train_batchsize,\n        class_mode='categorical',\n        interpolation='bilinear')\n \nvalidation_generator = validation_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/val_images',\n        target_size=(img_rows, img_cols),\n        batch_size=val_batchsize,\n        class_mode='categorical',\n        shuffle=False,\n        interpolation='bilinear')\n\n# dimensions of our images.\nimg_width, img_height = 334, 334\nbase_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\nbase_model.load_weights('../input/inaturalist/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\nfor layer in base_model.layers[:len(base_model.layers)-17]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-17:]:\n    layer.trainable = True\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((8, 8), strides=(8, 8), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_2 = Model(inputs=base_model.input, outputs=predictions)\noptimizer = Adam(0.0001)\nmodel_2.compile(loss=\"categorical_crossentropy\",\n              optimizer=optimizer,\n             metrics=[precision, recall, f1, 'acc'])\nlrate = LearningRateScheduler(step_decay)\ncheckpoint = ModelCheckpoint(\"./inception_natural_best.h5\",\n                             monitor=\"val_acc\",\n                             mode=\"max\",\n                             save_best_only = True,\n                             verbose=1)\n\nnb_train_samples = 1082\nnb_validation_samples= 103\nepochs=10\nbatch_size=16\n\nhistory = model_2.fit_generator(train_generator,\n                                 steps_per_epoch=nb_train_samples // batch_size,\n                                 epochs=epochs,\n                                 callbacks=[lrate, checkpoint],\n                                 validation_data=validation_generator,\n                                 validation_steps=nb_validation_samples // batch_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_2.evaluate(train_generator, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_2.evaluate(validation_generator, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inception V3 pretrained with INaturalist dataset give better result than the one on ImageNet"},{"metadata":{},"cell_type":"markdown","source":"## Inception V3 cropped image"},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"img_rows, img_cols = (224, 224)\ntrain_batchsize = 16\nval_batchsize = 16\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=30,\n      width_shift_range=0.3,\n      height_shift_range=0.3,\n      brightness_range=[0.2, 1.2],\n      horizontal_flip=True)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/train_images_cropped',\n        target_size=(img_rows, img_cols),\n        batch_size=train_batchsize,\n        class_mode='categorical',\n        interpolation='bilinear')\n \nvalidation_generator = validation_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/val_images_cropped',\n        target_size=(img_rows, img_cols),\n        batch_size=val_batchsize,\n        class_mode='categorical',\n        shuffle=False,\n        interpolation='bilinear')\n\n# dimensions of our images.\nimg_width, img_height = 224, 224\nbase_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\nbase_model.load_weights('../input/inaturalist/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\nfor layer in base_model.layers[:len(base_model.layers)-17]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-17:]:\n    layer.trainable = True\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((4, 4), strides=(4, 4), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_3 = Model(inputs=base_model.input, outputs=predictions)\noptimizer = Adam(0.0001)\nmodel_3.compile(loss=\"categorical_crossentropy\",\n              optimizer=optimizer,\n             metrics=[precision, recall, f1, 'acc'])\nlrate = LearningRateScheduler(step_decay)\ncheckpoint = ModelCheckpoint(\"./inception_natural_cropping_best_test_0.h5\",\n                             monitor=\"val_acc\",\n                             mode=\"max\",\n                             save_best_only = True,\n                             verbose=1)\n\nnb_train_samples = 941\nnb_validation_samples= 92\nepochs=10\nbatch_size=16\n\nhistory = model_3.fit(train_generator,\n                                 steps_per_epoch=nb_train_samples // batch_size,\n                                 epochs=epochs,\n                                 callbacks=[lrate, checkpoint],\n                                 validation_data=validation_generator,\n                                 validation_steps=nb_validation_samples // batch_size,\n                     verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_3.evaluate(validation_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model_3.evaluate(train_generator)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"## ORIGINAL IMAGES\n# dimensions of our images.\nimg_width, img_height = 334, 334\nbase_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\nbase_model.load_weights('../input/inaturalist/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\nfor layer in base_model.layers[:len(base_model.layers)-17]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-17:]:\n    layer.trainable = True\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((8, 8), strides=(8, 8), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.25)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_orig_predict = Model(inputs=base_model.input, outputs=predictions)\noptimizer = Adam(0.0001)\nmodel_orig_predict.compile(loss=\"categorical_crossentropy\",\n              optimizer=optimizer,\n             metrics=[precision, recall, f1, 'acc'])\nmodel_orig_predict.load_weights('./inception_natural_best.h5')\n\n\n## CROPPED IMAGES\n# dimensions of our images.\nimg_width, img_height = 224, 224\nbase_model = applications.InceptionV3(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\nbase_model.load_weights('../input/inaturalist/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5')\nfor layer in base_model.layers[:len(base_model.layers)-17]:\n    layer.trainable = False\nfor layer in base_model.layers[len(base_model.layers)-17:]:\n    layer.trainable = True\n# Add final layers\nx = base_model.output\nx = AveragePooling2D((4, 4), strides=(4, 4), name=\"avg_pool\")(x)\nx = Flatten(name=\"flatten\")(x)\nx = Dense(\n          512,\n          activation=\"swish\",\n          name=\"dense_1\",\n          kernel_initializer=\"he_uniform\")(x)\nx = Dropout(0.3)(x)\npredictions = Dense(\n    20,\n    activation=\"softmax\",\n    name=\"predictions\",\n    kernel_initializer=\"he_uniform\")(x)\nmodel_crop_predict = Model(inputs=base_model.input, outputs=predictions)\noptimizer = Adam(0.0001)\nmodel_crop_predict.compile(loss=\"categorical_crossentropy\",\n              optimizer=optimizer,\n             #metrics=[precision, recall, f1, 'acc'])\n                metrics=[f1, 'acc'])\nmodel_crop_predict.load_weights('./inception_crop_best.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions on original data\nimg_rows, img_cols = (334,334)\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/test_images',\n        target_size=(img_rows, img_cols),\n        batch_size=1,\n        class_mode=None,\n        shuffle=False,\n        interpolation='bilinear')\npredictions_inception_original = model_orig_predict.predict(test_generator)\n\n# Predictions on cropped image\nimg_rows, img_cols = (224,224)\n\ntest_datagen_crop = ImageDataGenerator(rescale=1./255)\n \ntest_generator_crop = test_datagen_crop.flow_from_directory(\n        '../input/bird-dasat/bird_dataset/test_images_cropped',\n        target_size=(img_rows, img_cols),\n        batch_size=1,\n        class_mode=None,\n        shuffle=False,\n        interpolation='bilinear')\npredictions_inception_crop = model_crop_predict.predict(test_generator_crop)\n\n# Get filenames list\nfilenames_orig = [x.split('/')[1][:-4] for x in test_generator.filenames]\nfilenames_crop = [x.split('/')[1][:-4] for x in test_generator_crop.filenames]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions with Max Probability between the two models"},{"metadata":{"trusted":true},"cell_type":"code","source":"category = []\nall_probas = []\nfor idx, elem in enumerate(filenames_orig):\n    inception_orig = (np.max(predictions_inception_original[idx]), np.argmax(predictions_inception_original[idx]))\n    try:\n        indice = filenames_crop.index(elem)\n        inception_crop = (np.max(predictions_inception_crop[indice]), np.argmax(predictions_inception_crop[indice]))\n        all_proba = [inception_orig, inception_crop]\n    except ValueError:\n        all_proba = [inception_orig]\n    max_proba, cat = all_proba[0]\n    for prob, label in all_proba[1:]:\n        if prob > max_proba:\n            max_proba = prob\n            cat = label\n    all_probas.append(all_proba)\n    category.append(cat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for lst in all_probas:\n    if len(lst) > 1:\n        if lst[0][1] != lst[1][1]:\n            print(lst)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'Id': filenames_orig, 'Category': category})\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('./submissions_2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.87741"},{"metadata":{},"cell_type":"markdown","source":"## Predictions with only inceptionv3orig on original image & inceptionv3crop on cropped images with condition"},{"metadata":{},"cell_type":"markdown","source":"if the difference between proba on original image and proba on cropped image is less than 0.15, I will take the prediction on original image (as the inceptionv3orig performs better than the inceptionv3crop)"},{"metadata":{"trusted":true},"cell_type":"code","source":"category = []\nall_probas = []\nthresh = 0.15\nfor idx, elem in enumerate(filenames_orig):\n    inception_orig = [np.max(predictions_inception_original[idx]), np.argmax(predictions_inception_original[idx])]\n    try:\n        indice = filenames_crop.index(elem)\n        inception_crop = [np.max(predictions_inception_crop[indice]), np.argmax(predictions_inception_crop[indice])]\n        if abs(inception_orig[0] - inception_crop[0]) < thresh:\n            inception_crop[0] = 0.\n        all_proba = [inception_orig, inception_crop]\n    except ValueError:\n        all_proba = [inception_orig]\n    max_proba, cat = all_proba[0]\n    for prob, label in all_proba[1:]:\n        if prob > max_proba:\n            max_proba = prob\n            cat = label\n    all_probas.append(all_proba)\n    category.append(cat)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_ = pd.DataFrame({'Id': filenames_orig, 'Category': category})\ndf_.to_csv('./submissions_3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"0.88387"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}